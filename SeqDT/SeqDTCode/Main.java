package SeqDTCode;

import java.util.ArrayList;

import java.util.Collections;

public class Main {
	public static void main(String[] args) throws Exception {
		int maxL = 5;
		// maximum length
		int g = 0;
		// gap constraint
		double threshold = 0.1;
		// maximum value of Gini index in one node
		int minNum = 1;
		// minimum number of sequence in one node
		double minSplit = 0.001;
		// minimum value of decreased impurity generated by segmentation
		int depth = 0;
		// maximum depth of the tree
		boolean pru = true;
		// determine whether to prune

		// 10 folder cross validation
		Main ten_folder = new Main();
		ReadFile f = new ReadFile();
		ArrayList<String> Totaldata = new ArrayList<String>();
		Totaldata = f.Read("./train.txt");
		ten_folder.kFolderValidation(Totaldata, g, maxL, threshold, minNum, minSplit, depth, pru, 10);

		// // 分段的训练方法
		// Main m = new Main();
		// ReadFile r = new ReadFile();
		// ArrayList<String> Tdata = new ArrayList<String>();
		// // training set
		// Tdata = r.Read("./train.txt");
		// Node root = new Node();
		// System.out.println("g:" + g + " maxL:" + maxL + " threshold:" + threshold + "
		// minNum:" + minNum + " depth:"
		// + depth + " pru:" + pru);
		// // create the decision tree
		// root = m.Train(Tdata, g, maxL, threshold, minNum, minSplit, depth, pru);
		// // testing set
		// Tdata = r.Read("./test.txt");
		// // test the decision tree constructed
		// float acc = m.Test(Tdata, g, root);
		// System.out.println("acc:" + acc);
	}

	public Main() {
	}

	/**
	 * build a decision tree based on the training set
	 * 
	 * @param train: training set
	 * @return root node of decision tree
	 * @throws Exception
	 */
	// 2021-11-13 k folder validation method added.
	public Node[] kFolderValidation(ArrayList<String> train, int g, int maxL, double threshold, int minNum,
			double minSplit, int depth, boolean pru, int k) throws Exception {
		// Tree[] trees = new Tree[k];
		Node[] roots = new Node[k];
		ArrayList<ArrayList<String>> folder = new ArrayList<ArrayList<String>>();
		Collections.shuffle(train);
		int oneFolderSize = train.size() / k;
		for (int i = 0; i < train.size(); i = i + oneFolderSize) {
			ArrayList<String> BUFF = new ArrayList<String>();
			for (int j = 0; j < oneFolderSize; j++) {
				BUFF.add(train.get(i + j));
			}
			folder.add(BUFF);
		}
		for (int j = 0; j < k; j++) {
			System.out.println("folder " + j);
			ArrayList<ArrayList<String>> trainset;
			trainset = new ArrayList<>(folder);
			ArrayList<String> Testset = trainset.get(j);
			trainset.remove(Testset);
			ArrayList<String> Trainset = new ArrayList<String>();

			for (ArrayList<String> arrayList : trainset) {
				Trainset.addAll(arrayList);
			}
			System.out.println(Testset.size() + " " + Trainset.size());
			// train each folder
			roots[j] = Train(Trainset, g, maxL, threshold, minNum, minSplit, depth, pru);
			float acc = Test(Testset, g, roots[j]);
			System.out.println(acc);
		}
		return roots;
	}

	public Node Train(ArrayList<String> train, int g, int maxL, double threshold, int minNum, double minSplit,
			int depth, boolean pru) throws Exception {

		Tree tree = new Tree(g, maxL, threshold, minNum, minSplit, depth, pru);
		Node root = new Node();
		root = tree.createRoot(train);
		return root;
	}

	/**
	 * use a decision tree to classify sequences
	 * 
	 * @param test: the testing set
	 * @param root: the root node of the decision tree
	 * @return classification accuracy
	 */
	public float Test(ArrayList<String> test, int g, Node root) {
		Classification cf = new Classification(g);
		int correct = 0;
		int all = 0;
		for (String str : test) {
			all++;
			String[] s = str.split("\t");
			String label = s[0];
			String[] dataInstanceForTesting = s[1].split(" ");
			String TempLabel = cf.getLabel(root, dataInstanceForTesting);
			if (TempLabel.equals(label)) {
				correct++;
			} else {
				// System.out.println(str);
			}
		}
		return (float) correct / all;
	}

}
